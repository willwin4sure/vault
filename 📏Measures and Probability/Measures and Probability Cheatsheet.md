## Measures

*See the [[⛺Measures Homepage]].*

A [[Measure Spaces#^c0c7fc|measurable space]] $(E,\mathcal{E})$ is a set $E$ equipped with a [[Measure Spaces#^f1d37f|$\sigma$-algebra]] $\mathcal{E}$. A [[Measure Spaces#^dde3c4|measure]] $\mu:\mathcal{E}\to[0,\infty]$ is a [[Set Functions#^164613|countably additive]] [[Set Functions#^b94a95|set function]], which gives rise to [[Measure Spaces#^607777|measure spaces]] $(E,\mathcal{E},\mu)$.

[[Carathéodory's Extension Theorem|Carathéodory's extension theorem]] allows us to define nontrivial measures by extending them from pre-measures on [[Rings and Algebras#^aed1d6|rings]] to fully fledged measures on the $\sigma$-algebra [[Measure Spaces#^0025c3|generated by]] the ring.

In proving [[Uniqueness of Extensions|uniqueness of this extension]], we encountered the notion of [[Pi and Lambda Systems|$\pi$- and $\lambda$-systems]]: the former contains the minimum amount of information to fully determine a measure, while the latter contains all measure deductions.

If a set $E$ is equipped with a topology, we can define the [[Lebesgue Measure#^7eb63d|Borel $\sigma$-algebra]] $\mathcal{B}(E)$ on $E$ as the $\sigma$-algebra generated by the open sets. We write $\mathcal{B}=\mathcal{B}(\mathbb{R})$. The most important Borel measure on $\mathbb{R}$ is the [[Lebesgue Measure#^e05763|Lebesgue measure]], which agrees with lengths of intervals (the mass is uniformly spread).

In the study of probability, we are concerned with [[Probability Spaces#^4a2efb|probability spaces]] $(\Omega,\mathcal{F},\mathbb{P})$, which are characterized by the fact that $\mathbb{P}(\Omega)=1$. Then, the elements of $\mathcal{F}$ are referred to as [[Probability Spaces#^8c79d4|events]]. We define countable sets of events as [[Independence#^634d97|independent]] if every finite subset has a joint probability that factors. We can extend this definition to [[Independence#^fa0801|independence of sub-$\sigma$-algebras]].

Finally, we proved the useful [[Borel-Cantelli Lemmas|Borel-Cantelli lemmas]], which relate the sum of probabilities of events to the probability that infinitely many of them occur.

## Measurable Functions

*See the [[⛺Measurable Functions Homepage]].*

A [[Measurable Functions#^3c3914|measurable function]] $f:E\to E'$ between two measurable spaces $(E,\mathcal{E})$ and $(E',\mathcal{E}')$ satisfies that the pre-image of any measurable set is measurable.

When the codomain is $([0,\infty],\mathcal{B}([0,\infty]))$, we refer to $f$ simply as a non-negative measurable function (note that we allow $\infty$). If the codomain is left unspecified, we assume it is $(\mathbb{R},\mathcal{B})$.

Given some $f:E\to E'$, we can use it to push forward any measure $\mu$ on $E$ into the [[Image Measures#^94991f|image measure]] $\mu'=\mu \circ f^{-1}$ on $E'$: if we want to measure $A\subseteq E'$, just pull it back through $f$ then use $\mu$. Pushing the Lebesgue measure on $[0,1]$ through inverse CDFs allows us to construct all probability measures on $\mathbb{R}$; a more general form is the [[Image Measures#^a35ae2|Lebesgue-Stieltjes measure]].

A measurable function from a probability space is called a [[Random Variables#^e3ffe4|random variable]] $X:\Omega\to E$. Its [[Random Variables#^f7e134|law]] is the pushforward measure $\mu_{X}=\mathbb{P}\circ X^{-1}$ on $E$.

Finally, there are several (and different) notions of convergence of measurable functions: [[Convergence of Measurable Functions#^061df9|convergence almost everywhere]] (*almost surely*), [[Lp Norms#^86e9f4|convergence in $L^p$]], [[Convergence of Measurable Functions#^dfe486|convergence in measure]] (*in probability*), and [[Convergence of Measurable Functions#^8b5c0e|convergence in distribution]].

## Integration

*See the [[⛺Integration Homepage]].*

If $(E,\mathcal{E},\mu)$ is a measure space, and $m\mathcal{E}^{+}$ denotes the set of non-negative measurable functions, then there is a unique map $\mu:m\mathcal{E}^{+}\to[0,\infty]$, called the [[Lebesgue Integration#^6f8116|Lebesgue integral]] with respect to $\mu$, such that

1. $\mu(\mathbf{1}_{A})=\mu(A)$ for all $A\in \mathcal{E}$.
2. $\mu(\alpha f+\beta g)=\alpha \mu(f)+\beta \mu(g)$ for all $f,g\in m\mathcal{E}^{+}$ and $\alpha,\beta \in[0,\infty]$.
3. $\mu(f_{n})\to \mu(f)$ as $n\to \infty$ whenever $(f_{n}\in m\mathcal{E}^{+}:n\in \mathbb{N})$ is nondecreasing with pointwise limit $f$.

Finite linear combinations of indicator functions on measurable sets are called [[Lebesgue Integration#^a0fb65|simple functions]], and their integrals can be computed directly. The third property is called [[Monotone Convergence Theorem#^aedc13|monotone convergence]] and can be used to compute the integrals of arbitrary $f$ by rounding $f$ down to dyadic grid size via $f_{n}(x)=(2^{-n}\lfloor 2^{n}f(x) \rfloor)\land n$.

It is straightforward to see that for $f\in m\mathcal{E}^{+}$, $\mu(f)=0$ if and only if $f=0$ a.e.

Monotone convergence also implies the important [[Fatou-Lebesgue Theorem#^11e9b4|Fatou lemma]], which states that
$$
\mu \left( \liminf_{ n \to \infty } f_{n} \right) \leq \liminf_{ n \to \infty } \mu (f_{n}).
$$
This allows us to show the [[Dominated Convergence Theorem#^541a22|dominated convergence theorem]], which states that so long as $f_{n}$ is dominated by an integrable function $g$, then when $f_{n}\to f$ pointwise, $\mu(f_{n})\to \mu(f)$ as well. 

Monotone and dominated convergence allow us to *pass limits through integrals*. 

Another important operation for computations is *passing partial derivatives of one variable through integrals of another variable*, called [[Differentiation Under the Integral Sign#^df8870|differentiation under the integral sign]]. This is possible when the function involved is sufficiently nice.

Finally, we want to be able to integrate over multiple variables. Given two $\sigma$-finite measure spaces $(E_{1},\mathcal{E}_{1},\mu_{1})$ and $(E_{2},\mathcal{E}_{2},\mu_{2})$, the [[Product Measure#^40b30e|product $\sigma$-algebra]] $\mathcal{E}=\mathcal{E}_{1}\otimes \mathcal{E}_{2}$ on $E_{1}\times E_{2}$ consists of the $\sigma$-algebra generated by cylinder sets of the form $A_{1}\times A_{2}$ where $A_{1}\in \mathcal{E}_{1}$ and $A_{2}\in \mathcal{E}_{2}$. 

There is a unique [[Product Measure#^8d56b9|product measure]] $\mu$ on $\mathcal{E}$ such that $\mu(A_{1}\times A_{2})=\mu_{1}(A_{1})\mu_{2}(A_{2})$ since this defines $\mu$ on a generating $\pi$-system.

Finally, [[Fubini-Tonelli Theorem|Fubini-Tonelli]] tells us when we can *swap order of integration*: it works under assumptions of non-negativity or integrability.

## Norms, Inequalities, and Lebesgue Spaces

*See the [[⛺Norms and Inequalities Homepage]] and the [[⛺Lebesgue Spaces Homepage]].

For $p \in[1,\infty]$, we can define the [[Lp Norms#^ac55c6|$L^p$-norm]] of a measurable function $f$. When $p\neq \infty$, we write $\| f \|_{p}=\mu(|f|^{p})^{1/p}$. When $p=\infty$, we write $\| f \|_{\infty}=\inf\{ \lambda : |f|\leq\lambda \text{ a.e.} \}$.

