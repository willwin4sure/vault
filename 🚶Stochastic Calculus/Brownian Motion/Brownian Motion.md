Last time, we constructed a Brownian motion on $(\Omega,\mathcal{F},\mathbb{P})$. This is some continuous function on $I=[0,\infty)$. What is the distribution of these continuous functions?

Let $I=[0,\infty)$, and consider $C(I)=\{ \text{continuous }f:I\to \mathbb{R} \}\subseteq \mathbb{R}^{I}$. The larger space $\mathbb{R}^{I}$ has the product $\sigma$-algebra $\mathcal{B}_{\mathbb{R}}^{\otimes I}$. We can define a $\sigma$-algebra on $C(I)$ by
$$
\mathcal{G}=\mathcal{B}_{\mathbb{R}}^{\otimes I}|_{C(I)}=\{ C(I)\cap A : A\in \mathcal{B}_{\mathbb{R}}^{I} \}.
$$
Our Brownian motion induces an mapping $(\Omega,\mathcal{F},\mathbb{P})\to(C(I),\mathcal{G},P=B_{\#}\mathbb{P})$, where $P(G)=\mathbb{P}(B^{-1}(G))$ is the pushforward.

> [!claim]
> Even though $(\Omega,\mathcal{F},\mathbb{P})$ is not unique, $P$ is unique. This is called the ==Wiener measure==.

> [!proof]-
> Compute
> $$
> P(B_{t_{1}}\in A_{1},\dots,B_{t_{k}}\in A_{k})=\mathbb{P}(X_{t_{1}}\in A_{1},\dots,X_{t_{k}}\in A_{k}),
> $$
> as $\mathbb{P}(B_{t}=X_{t})=1$ for all $t$. However, the second probability is just for some multivariate Gaussian. This characterizes $P$ on a $\pi$-system generating $\mathcal{G}$, which suffices.

> [!definition] Definition (Canonical Brownian motion)
> The ==canonical Brownian motion== is a random element $W$ of $(C(I),\mathcal{G},P)$, i.e. the identity mapping.

Another interpretation of $\mathcal{G}=\mathcal{B}_{\mathbb{R}}^{\otimes I}|_{C(I)}$: a natural topology on $C(I)$ is uniform convergence on compact time intervals. This is metrizable by
$$
d(f,g)=\sum_{n\geq 1}^{} \frac{1}{2^{n}}\min\{ 1,\sup \{ |f(t)-g(t)| : 0\leq t\leq n \} \}.
$$
Note that $d(f,g)\leq 1$.

> [!claim]
> The Borel $\sigma$-algebra on $C(I)$ generated by the $d$-topology coincides with $\mathcal{G}$.

> [!proof]-
> Call the first object $\mathcal{G}'$; we will show that $\mathcal{G}=\mathcal{G}'$. 
> 
> First, let's show that $\mathcal{G}\subseteq \mathcal{G}'$. Pick a basic measurable subset $\{ B_{t_{1}}\in[a_{1},b_{1}],\dots,B_{t_{k}}\in[a_{k},b_{k}] \}\in \mathcal{G}$. This is also in $\mathcal{G}'$ since it is closed in the $d$-topology.
> 
> For the other direction $\mathcal{G}'\subseteq \mathcal{G}$, we can consider the $\varepsilon$-ball $\{ g : d(f,g)<\varepsilon \}\in \mathcal{G}'$. We can measure $d(f,g)$ for $f,g\in C(I)$ by looking at $f$ and $g$ on $I\cap \mathbb{Q}$. Since $\mathbb{Q}$ is countable, it is also measurable with respect to $\mathcal{G}$.

TODO: move above to construction of BM

---

## Evolution Over Time

So far, we've viewed Brownian motion as a random function, where there is some randomness and we get a continuous sample path.

For the rest of today, we will discuss viewing BM as an evolution over time.

Let $\mathcal{F}_{t}=\sigma(B_{s}:0\leq s\leq t)$ and set
$$
\mathcal{F}_{t+}=\bigcap_{s>t}^{}\mathcal{F}_{s}.
$$
Intuitively, this gives an "infinitesimal amount of information" past time $t$, e.g. a right derivative.

> [!proposition] Proposition (Simple Markov property)
> Suppose that $(B_{t})_{t\geq 0}$ is a Brownian motion. Then, for any fixed time $s\geq 0$, the process $(B_{s+t}-B_{s})_{t\geq 0}$ is a Brownian motion independent of $\mathcal{F}_{s}$.

> [!proof]-
> Write $(\tilde{B}_{t})_{t\geq 0}$ as our new process. It is continuous because $B_{t}$ is. The covariance function is correct.
> 
> To show independence, use the fact that $B$ has independent increments.

> [!proposition] Proposition (Improved Markov property)
> In fact, $\tilde{B}\perp \mathcal{F}_{s+}$.

> [!proof]-
> Replace any $0$s with limits to $0$. Limits preserve independence.

> [!theorem] Theorem (Blumenthal $0$-$1$ Law)
> For any event $A\in \mathcal{F}_{0+}$, $\mathbb{P}(A)\in \{ 0,1 \}$. In other words, $\mathcal{F}_{0+}$ is $\mathbb{P}$-trivial.

> [!proof]-
> By the previous proposition, $\sigma(B_{s}: s\geq 0)$ is independent of $\mathcal{F}_{0+}$. Yet $\mathcal{F}_{0+}$ is contained in $\sigma(B_{s}: s\geq 0)$, so it is independent to itself. Hence $\mathbb{P}$-trivial.

> [!proposition]
> Let $B$ be a standard Brownian motion. Then,
> 
> 1. $B$ will cross $0$ an infinite number of times, almost surely. In other words, almost surely $\sup \{ B_{s} : s \in[0,\varepsilon] \}>0$ and $\inf \{ B_{s} : s \in[0,\varepsilon] \}<0$, for all $\varepsilon>0$.
> 2. For any $a\in \mathbb{R}$, the hitting time $T_{a}=\inf\{ t : B_{t}=a \}$ is finite almost surely.

> [!proof]
> 1. Let $A_{\varepsilon}=\{ \sup(B_{s}:0\leq s\leq t)>0 \}$, and write $A=\bigcap_{\varepsilon>0}^{}A_{\varepsilon}=\bigcap_{n\geq 1}^{}A_{\frac{1}{n}}\in \mathcal{F}_{0+}$, which means that $\mathbb{P}(A)\in \{ 0,1 \}$. Yet $\mathbb{P}(A_{\varepsilon})\geq \mathbb{P}\left( B_{\frac{\varepsilon}{2}}>0 \right)=\frac{1}{2}$, so $\mathbb{P}(A)\geq \frac{1}{2}$ as well (this is just symmetry), meaning that $\mathbb{P}(A)=1$ exactly.
> 2. This follows by rescaling time and space. We can write
> $$
> 1=\mathbb{P}(\sup(B_{s}:0\leq s\leq t)>0)=\lim_{ \delta \downarrow 0 }\mathbb{P}(\sup \{ B_{s}: s \in[0,1] \}\geq \delta). 
> $$
> However, by Brownian scaling, this is just
> $$
> \lim_{ \delta \downarrow 0 } \mathbb{P}\left( \sup \left\{  \tilde{B}_{s} : 0\leq s\leq \left( \frac{a}{\delta} \right) ^{2}  \right\}\geq a \right) = \mathbb{P}(T_{a}<\infty),
> $$
> as desired.

> [!definition] Definition (Stopping time)
> A random variable $T$ taking values in $[0,\infty]$ is a ==stopping time== if $\{ T\leq t \}\in \mathcal{F}_{t}$ for all $t\geq 0$. If $T$ is a stopping time, then we write
$$
\mathcal{F}_{T}=\{ A : A\cap \{ T\leq t \}\in \mathcal{F}_{t}\text{ for all }t\geq 0  \}.
$$

> [!theorem] Theorem (Strong Markov Property)
> Let $B$ be a standard Brownian motion and $T$ be a stopping time with $\mathbb{P}(T<\infty)>0$. Under $\mathbb{P}(\bullet | T<\infty)$, $(B_{T+t}-B_{T})_{t\geq 0}$ is a standard Brownian motion independent of $\mathcal{F}_{T}$.

> [!proof]- Omitted
> Read in the book I guess.

[!example] Example (Reflection principle)
An important application. Suppose we want to compute
$$
\mathbb{P}(B_{t}\geq a\text{ for some }t\in[0,1]).
$$
Let $S_{t}=\sup(B_{s}: s\leq t)$. Then, we can write
$$
\mathbb{P}(S_{1}\geq a,B_{1}\leq b)=\mathbb{P}(B_{1}\geq 2a-b)
$$
by reflecting the Brownian motion after the first time it hits $a$, applying the strong Markov property.



