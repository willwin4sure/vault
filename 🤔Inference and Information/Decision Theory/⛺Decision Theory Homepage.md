#MIT #CS #stats #inference

This first section of the course is focused on making categorical decisions based on data. We will mainly focus on binary classification problems.

## Main Sequence

First, the basic Bayesian setup, where you have both a prior and a cost function. This solves to the Likelihood Ratio Test.

1. [[Bayesian Hypothesis Testing]]
2. [[The Likelihood Ratio Test]]

Next, learn a way of characterizing a decision rule by its detection and false-alarm rates. This lends to solving the Neyman-Pearson criterion, where we enforce neither a prior nor a cost function.

3. [[OC-LRT]]
4. [[Neyman-Pearson Hypothesis Testing]]

Learn why the basic deterministic LRT is insufficient in certain cases, and how time-sharing randomization suffices to optimize.

5. [[Discontinuous OC-LRTs]]
6. [[Randomized Decision Rules]]

Finally, learn another formulation where we have a cost function but no prior, and model nature as responding to our decision rule with an adversarial prior.

7. [[Minimax Hypothesis Testing]]

---

**Next:** [[â›ºEstimation Homepage]]