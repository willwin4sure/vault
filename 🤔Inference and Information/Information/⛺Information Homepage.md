#MIT #CS #stats #inference 

Now, we turn to the study of information theory. 

## Main Sequence

First, a discussion of measures of information: entropy, conditional entropy, mutual information, and KL divergence. 

1. [[Generalized Bayesian Decision Theory]]
2. [[Information Measures]]
3. [[The Data Processing Inequality]]
4. [[KL Divergence]]
5. [[Other Divergence Families]]

<<<<<<< HEAD
6. [[The Probability Simplex]]
7. [[Information Projection and Pythagoras' Theorem]]
8. [[Linear Families]]
9. [[Orthogonal Families]]

10. [[Modeling as Inference]]
11. 

---
=======
Next, a discussion of information *geometry*, where we investigate the pseudo-geometry induced by the KL divergence (somewhat analogous to squared Euclidean distance) on the space of distributions.

6. [[The Probability Simplex]]
>>>>>>> 75491ed30641e1b38d47a8d674db36804d48c689
