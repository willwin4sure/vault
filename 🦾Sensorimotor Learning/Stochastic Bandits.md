The multi-armed bandit problem is not hard if every reward is deterministic: then you could simply try each arm and use the best one.

The difficulty comes from the fact that the reward is stochastic: the reward of each arm is drawn from some distribution.

One strategy is called ==explore first==. 