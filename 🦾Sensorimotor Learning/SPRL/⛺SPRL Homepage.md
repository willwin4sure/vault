#MIT #CS #ML #RL 

This is my final project for the class, code found [here](https://github.com/willwin4sure/sprl). I worked with Eric Yang and Kartik Pingle on building a scalable self-play reinforcement learning framework to solve various two-player zero-sum abstract strategy games from scratch, without human knowledge. Rowechen Zhong also made some contributions for fun.

We aimed to solve the following games, in order of increasing difficulty:

* Connect Four
* Pentago
* Checkers
* Othello
* Hex
* Chess
* Go

Of course, we can always adjust the board size of these games, which can greatly change the difficulty of the task.

Our work is based primarily on the [AlphaGo Zero paper](https://www.nature.com/articles/nature24270), as well as the following [AlphaZero paper](https://arxiv.org/abs/1712.01815). I've compiled a useful list of resources [[References for SPRL|here]].

---

**Next:** [[The UCT Algorithm]]

